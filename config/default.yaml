      # Recommended not to change, use it for copy-paste
FRAMEWORKS_AVAILABLE: ["torchvision", "segmentation_models_pytorch"]

# Recommended not to change, use it for copy-paste
MODELS_AVAILABLE:
    torchvision: ["fcn_resnet50",
                  "fcn_resnet101",
                  "deeplabv3_resnet50",
                  "deeplabv3_resnet101",
                  "deeplabv3_mobilenet_v3_large",
                  "lraspp_mobilenet_v3_large"]
                  
# Recommended not to change, use it for copy-paste
DECODER_AVAILABLE: ["unet", "unetplusplus", 
                    "manet", "linknet", 
                    "fpn", "pspnet", 
                    "deeplabv3", "deeplabv3plus", "pan"]

# Recommended not to change, use it for copy-paste
ENCODER_AVAILABLE: ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 
                    'resnext50_32x4d', 'resnext101_32x4d', 'resnext101_32x8d', 'resnext101_32x16d', 'resnext101_32x32d', 'resnext101_32x48d', 
                    'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn107', 'dpn131', 
                    'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 
                    'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 
                    'densenet121', 'densenet169', 'densenet201', 'densenet161', 
                    'inceptionresnetv2', 'inceptionv4', 
                    'efficientnet-b0', 'efficientnet-b1', 'efficientnet-b2', 'efficientnet-b3', 'efficientnet-b4', 'efficientnet-b5', 'efficientnet-b6', 'efficientnet-b7', 
                    'mobilenet_v2', 'xception', 
                    'timm-efficientnet-b0', 'timm-efficientnet-b1', 'timm-efficientnet-b2', 'timm-efficientnet-b3', 'timm-efficientnet-b4', 
                    'timm-efficientnet-b5', 'timm-efficientnet-b6', 'timm-efficientnet-b7', 'timm-efficientnet-b8', 'timm-efficientnet-l2', 
                    'timm-tf_efficientnet_lite0', 'timm-tf_efficientnet_lite1', 'timm-tf_efficientnet_lite2', 'timm-tf_efficientnet_lite3', 'timm-tf_efficientnet_lite4', 
                    'timm-resnest14d', 'timm-resnest26d', 'timm-resnest50d', 'timm-resnest101e', 'timm-resnest200e', 'timm-resnest269e', 
                    'timm-resnest50d_4s2x40d', 'timm-resnest50d_1s4x24d', 
                    'timm-res2net50_26w_4s', 'timm-res2net101_26w_4s', 'timm-res2net50_26w_6s', 'timm-res2net50_26w_8s', 'timm-res2net50_48w_2s', 'timm-res2net50_14w_8s', 'timm-res2next50', 
                    'timm-regnetx_002', 'timm-regnetx_004', 'timm-regnetx_006', 'timm-regnetx_008', 'timm-regnetx_016', 'timm-regnetx_032', 
                    'timm-regnetx_040', 'timm-regnetx_064', 'timm-regnetx_080', 'timm-regnetx_120', 'timm-regnetx_160', 'timm-regnetx_320', 
                    'timm-regnety_002', 'timm-regnety_004', 'timm-regnety_006', 'timm-regnety_008', 'timm-regnety_016', 'timm-regnety_032', 
                    'timm-regnety_040', 'timm-regnety_064', 'timm-regnety_080', 'timm-regnety_120', 'timm-regnety_160', 'timm-regnety_320', 
                    'timm-skresnet18', 'timm-skresnet34', 'timm-skresnext50_32x4d', 
                    'timm-mobilenetv3_large_075', 'timm-mobilenetv3_large_100', 'timm-mobilenetv3_large_minimal_100', 
                    'timm-mobilenetv3_small_075', 'timm-mobilenetv3_small_100', 'timm-mobilenetv3_small_minimal_100', 
                    'timm-gernet_s', 'timm-gernet_m', 'timm-gernet_l']

# Recommended not to change, use it for copy-paste
CRITERION_AVAILABLE:
    # available_framework: [avaliable criterions]
    torch.nn: ["CrossEntropy"]
    pytorch_toolbelt: ["BalancedBCEWithLogitsLoss", "BiTemperedLogisticLoss", "BinaryBiTemperedLogisticLoss", 
                       "DiceLoss", "FocalCosineLoss", "BinaryFocalLoss", "FocalLoss", "JaccardLoss", "JointLoss", 
                       "WeightedLoss", "BinaryLovaszLoss", "LovaszLoss", "SoftBCEWithLogitsLoss", 
                       "SoftCrossEntropyLoss", "BinarySoftF1Loss", "SoftF1Loss", "WingLoss"]
    

SELECTED:
    # # 1. IF you use torchvision model
    # FRAMEWORK: "torchvision"
    # MODEL: "lraspp_mobilenet_v3_large" # also used for submission save.
    # MODEL_CFG:
    #     pretrained: True
    
    
    # 2. IF you use smp model
    # smp.create_model(**cfg["SELECTED"]["MODEL_CFG"]) 형태로 사용하기 때문에
    # MODEL_CFG 아래는 소문자가 좋습니다. (PRETRAINED -> pretrained)
    FRAMEWORK: "segmentation_models_pytorch"
    MODEL_CFG:
        arch: "fpn"                 # DECODER
        encoder_name: "timm-efficientnet-b6" # ENCODER
        encoder_weights: "noisy-student"     # ENCODER 마다 가능한 DATASET 상이. 
                                             # (https://smp.readthedocs.io/en/latest/encoders.html)
                                             # ("imagenet", "advpros", "noisy-student" 등)
        in_channels: 3 # fixed
        classes: 11    # fixed
    
    CRITERION: 
        FRAMEWORK: "pytorch_toolbelt"
        USE: "SoftCrossEntropyLoss"
        CFG:
        


SEED: 21

EXPERIMENTS:
    NUM_EPOCHS: 30
    BATCH_SIZE: 16
    LEARNING_RATE: 1e-4
    NUM_WORKERS: 4
    VAL_EVERY: 3
    
    KFOLD:
        TURN_ON: True
        NUM_FOLD: 5
    
    AUTOCAST_TURN_ON: True
    
    WNB:
        TURN_ON: True
        INIT:
            entity: "ai_tech_level2-cv-18"
            project: "seunghun_T2042"
            name: "fpn_timm-efficientnet-b6_211102_13h" # recommended to change if wnb is turn-on.
    
    
    SAVED_DIR: 
        BEST_MODEL: "./saved"
        SUBMISSION: "./submission"
    
    
    TRAIN_TRANS: # ToTensorV2 는 기본으로 들어가있고 Albumentation 의 augmentation 이용
        GridDistortion: 
            p: 1.0
        RandomGridShuffle:
            p: 1.0
        RandomResizedCrop:
            height: 512
            width: 512
            p: 1.0
        HorizontalFlip:
            p: 1.0
        VerticalFlip:
            p: 1.0
        GridDropout:
            p: 1.0
        ElasticTransform:
            p: 1.0
        
    TEST_n_VAL_TRANS: # ToTensorV2 는 기본으로 들어가있음.
    
    TTA:
        TURN_ON: True
        AVAILABLE_LIST: # only support 2 below TTAs.
            VERTICAL_FLIP_TURN_ON: True
            HORIZONTAL_FLIP_TURN_ON: True
            

DATASET:
    PATH: "../segmentation/input/data"
    ANNS_FILE_NAME: "train_all.json"
    TRAIN_FILE_NAME: "train_all.json"
    # TRAIN_FILE_NAME: "val.json"
    VAL_FILE_NAME: "val.json" # not used if you set "KFOLD TURN ON - True".
    TEST_FILE_NAME: "test.json"
    NUM_CLASSES: 11

